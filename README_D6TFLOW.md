# d6tflow Media AI Pipeline ğŸš€

[![d6tflow](https://img.shields.io/badge/workflow-d6tflow-blue)](https://github.com/d6t/d6tflow)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://python.org)
[![OpenAI](https://img.shields.io/badge/AI-OpenAI-green)](https://openai.com)

> **A robust, production-ready workflow system for AI-powered media analysis**

This directory now contains a complete d6tflow implementation of the Media AI Pipeline, transforming it from simple scripts into a sophisticated workflow engine with dependency management, caching, error handling, and scalable processing.

## ğŸ¯ What is d6tflow?

d6tflow is a Python library for building robust data science workflows. It provides:
- **Automatic dependency management** - Tasks only run when needed
- **Intelligent caching** - Results are cached to avoid re-computation  
- **Error resilience** - Failed tasks don't break the entire pipeline
- **Incremental processing** - Only process what has changed
- **Parallel execution** - Run independent tasks concurrently

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TD
    A[Media Files] --> B[Discovery Tasks]
    B --> C[Analysis Tasks]
    C --> D[Storage Tasks]
    D --> E[Query Interface]
    
    B1[DiscoverScreenshots] --> C1[BatchScreenshotAnalysis]
    B2[DiscoverVideos] --> C2[BatchVideoAnalysis]
    B3[DiscoverLectures] --> C3[BatchLectureProcessing]
    
    C1 --> D1[SaveToAirtable]
    C2 --> D1
    C3 --> D2[VectorDatabase]
    
    D1 --> E[QueryMediaData]
    D2 --> E
```

## ğŸ“ File Structure

```
media_ai_pipeline/
â”œâ”€â”€ d6tflow Implementation
â”‚   â”œâ”€â”€ d6tflow_config.py           # Configuration and parameters
â”‚   â”œâ”€â”€ d6tflow_ingestion_tasks.py  # File discovery tasks
â”‚   â”œâ”€â”€ d6tflow_screenshot_tasks.py # Screenshot analysis 
â”‚   â”œâ”€â”€ d6tflow_video_tasks.py      # Video analysis
â”‚   â”œâ”€â”€ d6tflow_lecture_tasks.py    # Lecture processing
â”‚   â”œâ”€â”€ d6tflow_storage_tasks.py    # Data storage and queries
â”‚   â”œâ”€â”€ d6tflow_pipeline.py         # Pipeline orchestrators
â”‚   â””â”€â”€ d6tflow_cli.py              # Command-line interface
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ D6TFLOW_GUIDE.md            # Complete user guide
â”‚   â”œâ”€â”€ D6TFLOW_IMPLEMENTATION_SUMMARY.md
â”‚   â”œâ”€â”€ example_d6tflow_usage.py    # Practical examples
â”‚   â””â”€â”€ README_D6TFLOW.md           # This file
â”‚
â”œâ”€â”€ Generated Directories  
â”‚   â”œâ”€â”€ d6tflow_data/               # Task results cache
â”‚   â””â”€â”€ workflow_outputs/           # Pipeline outputs
â”‚
â””â”€â”€ Original Pipeline (unchanged)
    â”œâ”€â”€ media_pipeline.py
    â”œâ”€â”€ screenshot_analyzer.py
    â”œâ”€â”€ video_analyzer.py
    â”œâ”€â”€ lecture_processor.py
    â””â”€â”€ ... (other original files)
```

## ğŸš€ Quick Start

### 1. Check System Status
```bash
python d6tflow_cli.py status
```

### 2. Test with Screenshots (Recommended First Step)
```bash
# Analyze just 3 screenshots to test the system
python d6tflow_cli.py run --screenshots --limit 3
```

### 3. Run Full Pipeline
```bash
# Small test run
python d6tflow_cli.py run --full \
  --screenshot-limit 5 \
  --video-limit 2 \
  --lecture-limit 1

# Production run (adjust limits as needed)
python d6tflow_cli.py run --full \
  --screenshot-limit 50 \
  --video-limit 20 \
  --lecture-limit 10
```

### 4. Query Your Media
```bash
python d6tflow_cli.py query "screenshots with Python code"
python d6tflow_cli.py query "error messages" --type screenshots
python d6tflow_cli.py query "machine learning" --type lectures
```

### 5. Export Results
```bash
python d6tflow_cli.py export --format json --output my_analysis.json
```

## ğŸ’¡ Key Benefits

### vs. Original Pipeline
| Feature | Original | d6tflow Version |
|---------|----------|-----------------|
| **Caching** | None | âœ… Automatic |
| **Error Handling** | Basic | âœ… Robust |
| **Dependencies** | Manual | âœ… Automatic |
| **Incremental** | No | âœ… Yes |
| **Parallel** | No | âœ… Yes |
| **Resumable** | No | âœ… Yes |
| **Scalable** | Limited | âœ… Configurable |

### Real-World Benefits
- ğŸ”„ **Resume interrupted runs** - If processing fails, restart where you left off
- âš¡ **Skip completed work** - Only reprocess changed files
- ğŸ›¡ï¸ **Error isolation** - One failed file doesn't stop the entire batch
- ğŸ“Š **Better monitoring** - Track progress and success rates
- âš™ï¸ **Flexible execution** - Run full pipeline or specific components
- ğŸ” **Rich querying** - Search processed media with natural language

## ğŸ›ï¸ Configuration

### Key Settings (`d6tflow_config.py`)
```python
class PipelineConfig:
    DEFAULT_SCREENSHOT_LIMIT = 10    # Adjust for your needs
    DEFAULT_VIDEO_LIMIT = 5
    DEFAULT_LECTURE_LIMIT = 3
    
    BATCH_SIZE_SCREENSHOTS = 5       # Balance speed vs memory
    BATCH_SIZE_VIDEOS = 2
    
    MAX_WORKERS = 3                  # Parallel processing
```

### Environment Variables
```bash
# Required
OPENAI_API_KEY=your_key_here

# Optional
AIRTABLE_API_KEY=your_airtable_key
MEDIA_AIRTABLE_BASE_ID=your_base_id
HUGGING_FACE_TOKEN=your_hf_token
```

## ğŸ“š Usage Patterns

### Command Line
```bash
# Development/Testing
python d6tflow_cli.py run --screenshots --limit 5
python d6tflow_cli.py run --videos --limit 2 --keyframes 8

# Production
python d6tflow_cli.py run --full --recent-hours 168  # Last week
python d6tflow_cli.py export --format json --output weekly.json

# Maintenance  
python d6tflow_cli.py cleanup --days 30 --dry-run
```

### Python API
```python
from d6tflow_pipeline import run_full_pipeline, query_pipeline_results

# Run pipeline
results = run_full_pipeline(
    screenshot_limit=20,
    video_limit=10,
    recent_hours=72  # Last 3 days
)

# Query results
searches = query_pipeline_results("debugging screenshots")
```

## ğŸ”§ Advanced Features

### Custom Task Parameters
```python
# Fine-tune processing
from d6tflow_config import TaskParams

params = TaskParams.screenshot_analysis(
    limit=50,
    recent_hours=48
)
```

### Selective Pipeline Execution
```bash
# Skip certain components
python d6tflow_cli.py run --full --no-lectures --no-airtable

# Process only recent files
python d6tflow_cli.py run --videos --recent-hours 24
```

### Batch Size Optimization
```python
# In d6tflow_config.py - adjust based on your system
BATCH_SIZE_SCREENSHOTS = 10  # More memory, faster
BATCH_SIZE_SCREENSHOTS = 2   # Less memory, slower
```

## ğŸ› Troubleshooting

### Common Issues

**"Task already complete" but you want to re-run:**
```bash
# Clear specific task cache
find d6tflow_data -name "*ScreenshotAnalysis*" -delete

# Or clear all caches (nuclear option)
rm -rf d6tflow_data/
```

**Out of memory errors:**
```python
# Reduce batch sizes in d6tflow_config.py
BATCH_SIZE_SCREENSHOTS = 2
BATCH_SIZE_VIDEOS = 1
```

**Missing files or directories:**
```bash
# Check system status
python d6tflow_cli.py status --verbose
```

### Debug Mode
```python
import logging
logging.basicConfig(level=logging.DEBUG)
# Then run your pipeline
```

## ğŸ“– Documentation

- **[D6TFLOW_GUIDE.md](D6TFLOW_GUIDE.md)** - Complete user guide with examples
- **[example_d6tflow_usage.py](example_d6tflow_usage.py)** - 7 practical examples
- **[D6TFLOW_IMPLEMENTATION_SUMMARY.md](D6TFLOW_IMPLEMENTATION_SUMMARY.md)** - Technical details

## ğŸ†š When to Use d6tflow vs Original

### Use d6tflow When:
- âœ… Processing large media collections (100+ files)
- âœ… Need to resume interrupted processing
- âœ… Want to avoid reprocessing unchanged files  
- âœ… Running regular/scheduled analysis
- âœ… Need robust error handling
- âœ… Want parallel processing
- âœ… Building production workflows

### Use Original When:
- âœ… Quick one-off analysis (< 20 files)
- âœ… Testing new features
- âœ… Learning how the system works
- âœ… Simple scripting needs

## ğŸš¦ Getting Started Recommendation

1. **First time?** Start with: `python d6tflow_cli.py status`
2. **Test run:** `python d6tflow_cli.py run --screenshots --limit 3`
3. **Learn more:** Read [D6TFLOW_GUIDE.md](D6TFLOW_GUIDE.md)
4. **Production:** Scale up limits based on your needs

## ğŸ¤ Integration

The d6tflow implementation:
- âœ… **Preserves** all original functionality
- âœ… **Extends** with workflow management
- âœ… **Coexists** with original scripts
- âœ… **Uses** the same analysis engines
- âœ… **Maintains** compatibility with Airtable
- âœ… **Adds** CLI and Python APIs

You can use both systems simultaneously - d6tflow for production workflows and the original scripts for quick experiments.

---

## ğŸ‰ Ready to Use!

Your Media AI Pipeline now has two modes:

1. **Original Mode** - Direct scripts for quick analysis
2. **d6tflow Mode** - Production workflow engine

Choose the right tool for your task and enjoy robust, scalable media analysis! ğŸš€

For questions or issues, check the documentation or examine the example files.
